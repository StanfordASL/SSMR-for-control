{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiabatic SSM model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite-horizon prediction accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook quantifies the predictive power of adiabatic SSM models by doing finite-horizon predictions across the robot's workspace and evaluating the corresponding prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, split, isdir\n",
    "import pickle\n",
    "import yaml\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import yaml\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils as utils\n",
    "import plot_utils as plot\n",
    "from interpolators import InterpolatorFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiabatic SSM settings\n",
    "ROMOrder = 3\n",
    "# N_samples = 100\n",
    "DT = 0.01\n",
    "INTERPOLATE = \"reduced_coords\" # \"xyz\" # \"xy\" # \"reduced_coords\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trunk settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = \"delay-embedding\" # \"delay-embedding\" # \"pos-vel\" # \n",
    "N_DELAY = 4 # only relevant if observables is \"delay-embedding\"\n",
    "TIP_NODE = 51\n",
    "N_NODES = 709\n",
    "INPUT_DIM = 8\n",
    "DT = 0.01\n",
    "\n",
    "rDOF = 3\n",
    "oDOF = 3\n",
    "SSMDim = 6\n",
    "\n",
    "robot_dir = \"../../../soft-robot-control/examples/trunk\"\n",
    "rest_file = join(robot_dir, 'rest_qv.pkl')\n",
    "\n",
    "# load rest position\n",
    "with open(rest_file, 'rb') as f:\n",
    "    rest_data = pickle.load(f)\n",
    "    rest_q = rest_data['q'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099']\n",
      "['000', '001', '002', '003', '004', '005', '006', '007', '008']\n",
      "N_models: 109\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/media/jonas/Backup Plus/jonas_soft_robot_data/trunk_adiabatic_10ms_N=100_sparsity=0.95\" # 9\" # 147\" # 33_handcrafted\" #  # \n",
    "model_names = [name for name in sorted(listdir(model_dir)) if isdir(join(model_dir, name))]\n",
    "print(model_names)\n",
    "\n",
    "USE_DEFAULT_MODELS = True\n",
    "\n",
    "default_model_dir = \"/media/jonas/Backup Plus/jonas_soft_robot_data/trunk_adiabatic_10ms_N=9\"\n",
    "default_model_names = [name for name in sorted(listdir(default_model_dir)) if isdir(join(default_model_dir, name))]\n",
    "print(default_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_models = \"only_default\" # \"sparsify\" # \"outlier_removal\" # \"all\" # \"test_results\" # \"fixed_grid\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute observables (delay embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if observables == \"delay-embedding\":\n",
    "    N_DELAY = 4\n",
    "    # observables are position of tip + n_delay delay embeddings of the tip position\n",
    "    assemble_observables = lambda oData: utils.delayEmbedding(oData, up_to_delay=N_DELAY)\n",
    "elif observables == \"pos-vel\":\n",
    "    # observables is position and velocity of tip node\n",
    "    def assemble_observables(oData):\n",
    "        if oData.shape[0] > 6:\n",
    "            tip_node_slice = np.s_[3*TIP_NODE:3*TIP_NODE+3]\n",
    "        else:\n",
    "            tip_node_slice = np.s_[:3]\n",
    "        return np.vstack((oData[tip_node_slice, :], np.gradient(oData[tip_node_slice, :], DT, axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load local SSM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_models: 9\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "test_results = []\n",
    "\n",
    "if USE_DEFAULT_MODELS:\n",
    "    for model_name in default_model_names:\n",
    "        dir = join(default_model_dir, model_name, f\"SSMmodel_{observables}_ROMOrder=3_globalV_fixed-delay\")\n",
    "        with open(join(dir, \"SSM_model.pkl\"), \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "            models.append(model)\n",
    "        with open(join(dir, \"test_results.yaml\"), \"rb\") as f:\n",
    "            test_results_dict = yaml.safe_load(f)\n",
    "            test_results.append([test_results_dict['like training data']['RMSE'], test_results_dict['open-loop_circle']['RMSE']])\n",
    "\n",
    "if filter_models != \"only_default\":\n",
    "    for model_name in model_names:\n",
    "        dir = join(model_dir, model_name, f\"SSMmodel_{observables}_globalV\")\n",
    "        with open(join(dir, \"SSM_model.pkl\"), \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "            models.append(model)\n",
    "        with open(join(dir, \"test_results.yaml\"), \"rb\") as f:\n",
    "            test_results_dict = yaml.safe_load(f)\n",
    "            test_results.append([test_results_dict['like training data']['RMSE'], test_results_dict['open-loop_circle']['RMSE']])\n",
    "\n",
    "V = [model['model']['V'] for model in models]\n",
    "r_coeff = [model['model']['r_coeff'] for model in models]\n",
    "w_coeff = [model['model']['w_coeff'] for model in models]\n",
    "v_coeff = [model['model']['v_coeff'] for model in models]\n",
    "B_r = [model['model']['B'] for model in models]\n",
    "q_bar = [(model['model']['q_eq'] - rest_q)[TIP_NODE*3:TIP_NODE*3+3] for model in models]\n",
    "u_bar = [model['model']['u_eq'] for model in models]\n",
    "ROMOrder = models[0]['params']['ROM_order']\n",
    "SSMOrder = models[0]['params']['SSM_order']\n",
    "for model in models:\n",
    "    assert model['params']['ROM_order'] == ROMOrder\n",
    "    assert model['params']['SSM_order'] == SSMOrder\n",
    "test_results = np.array(test_results)\n",
    "\n",
    "N_models = len(V)\n",
    "print(\"N_models:\", N_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.0116741 ,  0.09136295,  0.0383846 ,  0.00076458, -0.00433124,  0.00074858]), array([ 72.9267292 , -20.04814538, -28.61369534,   3.39920343,   1.74130791,  -1.4508973 ]), array([-32.36741758, -62.47260605, -37.32622321,  -1.50355753,   2.99363918,  -1.87813233]), array([-73.89207721,  33.43785334,   3.89146107,  -3.11097681,  -1.89676717,  -1.53847375]), array([29.37044068, 73.49785929, 12.97434427,  1.68149513, -3.06984472, -1.00990627]), array([ 41.81167278, -82.87095552, -66.49121622,   1.95456372,   4.76607361,  -3.35980064]), array([-108.11923851,  -27.69264586,  -34.11427275,   -4.68187634,    1.04114646,   -3.55186094]), array([-44.18260968, 106.98101026,  15.62895123,  -1.40198947,  -4.94621196,  -2.6718042 ]), array([101.23388332,  54.22021898, -16.27941313,   5.04466878,  -1.35641969,  -2.5637134 ])]\n"
     ]
    }
   ],
   "source": [
    "if INTERPOLATE == \"xyz\":\n",
    "    psi_eq = [q_bar[i][:3] for i in range(N_models)]\n",
    "elif INTERPOLATE == \"xy\":\n",
    "    psi_eq = [q_bar[i][:2] for i in range(N_models)]\n",
    "elif INTERPOLATE == \"reduced_coords\":\n",
    "    psi_eq = [V[i].T @ np.tile(q_bar[i], 5) for i in range(N_models)]\n",
    "# psi_eq\n",
    "# print(u_bar)\n",
    "# print(np.sum([u == 0 for u in u_bar], axis=1))\n",
    "# print(np.mean(np.sum([u == 0 for u in u_bar], axis=1)))\n",
    "print(psi_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "\n",
    "R_linear_part = [r[:, :6] for r in r_coeff]\n",
    "eigenvalues_real_part = [np.real(np.linalg.eigvals(r)) for r in R_linear_part]\n",
    "metric = [np.linalg.norm(eigenvalues, ord=-np.inf) for eigenvalues in eigenvalues_real_part]\n",
    "\n",
    "psi_eq_array = np.array(psi_eq)\n",
    "color_by_metric = False\n",
    "\n",
    "if INTERPOLATE == \"xyz\":\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    if color_by_metric:\n",
    "        sc = ax.scatter(psi_eq_array[:, 0], psi_eq_array[:, 1], psi_eq_array[:, 2], marker=\"o\", c=metric, vmax=None, cmap='viridis')\n",
    "    else:\n",
    "        sc = ax.scatter(psi_eq_array[:, 0], psi_eq_array[:, 1], psi_eq_array[:, 2], marker=\"o\", color=\"darkblue\")\n",
    "    for i in range(N_models):\n",
    "        ax.text(psi_eq_array[i, 0], psi_eq_array[i, 1], psi_eq_array[i, 2], str(i), size=10, zorder=1, color='k')\n",
    "    ax.set_zlabel(r\"$z$ [mm]\")\n",
    "else:\n",
    "    ax = plt.axes()\n",
    "    if INTERPOLATE == \"xy\":\n",
    "        color = \"tab:blue\"\n",
    "    elif INTERPOLATE == \"reduced_coords\":\n",
    "        color = \"tab:orange\"\n",
    "    if color_by_metric:\n",
    "        sc = ax.scatter(psi_eq_array[:, 0], psi_eq_array[:, 1], marker=\"o\", c=metric, vmax=None, cmap=\"viridis\")\n",
    "    else:\n",
    "        sc = ax.scatter(psi_eq_array[:, 0], psi_eq_array[:, 1], marker=\"o\", color=color)\n",
    "if INTERPOLATE in  [\"xy\", \"xyz\"]:\n",
    "    ax.set_xlabel(r\"$x$ [mm]\")\n",
    "    ax.set_ylabel(r\"$y$ [mm]\")\n",
    "elif INTERPOLATE == \"reduced_coords\":\n",
    "    ax.set_xlabel(r\"$x_1$\")\n",
    "    ax.set_ylabel(r\"$x_2$\")\n",
    "ax.set_aspect(\"equal\")\n",
    "if color_by_metric:\n",
    "    plt.colorbar(sc, ax=ax, label=r\"$||Re(\\lambda)||_{\\infty}$\")\n",
    "    fig.suptitle(\"Slowest decay mode of the ROM's linear part\")\n",
    "fig.savefig(join(model_dir, f\"models_in_{INTERPOLATE}.svg\"), dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsify grid: Start with origin model and add more models while ensuring that each model is the only one inside a ball with size $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"sparsify\":\n",
    "    radius = 10\n",
    "    use_models = [0]\n",
    "    for model_name_i in model_names:\n",
    "        model_i = int(model_name_i)\n",
    "        add_model = True\n",
    "        for model_j in use_models:\n",
    "            distance = np.linalg.norm(psi_eq[model_i] - psi_eq[model_j])\n",
    "            if distance < radius:\n",
    "                add_model = False\n",
    "                break\n",
    "        if add_model:\n",
    "            use_models.append(model_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix regular grid. Around each grid point, pick the available model with minimum $|u|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"fixed_grid\":\n",
    "    ranges = {\n",
    "        'x': [-45, 45],\n",
    "        'y': [-45, 45],\n",
    "        'z': [0, -20]\n",
    "    }\n",
    "    n_grid = {\n",
    "        'x': 7,\n",
    "        'y': 7,\n",
    "        'z': 3,\n",
    "    }\n",
    "    x = np.linspace(ranges['x'][0], ranges['x'][1], n_grid['x'])\n",
    "    y = np.linspace(ranges['y'][0], ranges['y'][1], n_grid['y'])\n",
    "    z = np.linspace(ranges['z'][0], ranges['z'][1], n_grid['z'])\n",
    "    use_models = [0]\n",
    "    radius = 10\n",
    "    for zi in z:\n",
    "        for yi in y:\n",
    "            for xi in x:\n",
    "                if xi == 0 and yi == 0 and zi == 0:\n",
    "                    continue\n",
    "                # potential_models = []\n",
    "                # # find the models within a ball with radius 10mm around the point\n",
    "                # # choose model with smallest |u|\n",
    "                # for model_name_i in model_names:\n",
    "                #     model_i = int(model_name_i)\n",
    "                #     distance = np.linalg.norm([xi, yi, zi] - eq_q[model_i])\n",
    "                #     if distance < radius and model_i not in use_models:\n",
    "                #         potential_models.append(model_i)\n",
    "                # if potential_models:\n",
    "                #     use_models.append(min(potential_models, key=(lambda id: np.linalg.norm(u_bar[id]))))\n",
    "                min_dist_model = min([int(model_name) for model_name in model_names], key=(lambda id: np.linalg.norm(psi_eq[id] - [xi, yi, zi])))\n",
    "                if min_dist_model not in [int(model_name) for model_name in use_models]:\n",
    "                    use_models.append(min_dist_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out models based on test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"test_results\":\n",
    "    print(test_results[:, 0])\n",
    "    good_models = ~np.isnan(test_results[:, 0]) & (test_results[:, 0] < 0.3)\n",
    "    use_models = [int(model_name) for model_name in model_names if good_models[int(model_name)]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out models with large pre-tensionings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"small_pretensionings\":\n",
    "    bad_models = (np.linalg.norm(np.array(u_bar), axis=1) > 1000)\n",
    "    use_models = [int(model_name) for model_name in model_names if not bad_models[int(model_name)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"outlier_removal\":\n",
    "\n",
    "    ref_model = 0 # origin model\n",
    "    compare_coeffs = [r_coeff]\n",
    "\n",
    "    ref_coeff_array = np.concatenate([coeff[ref_model].flatten() for coeff in compare_coeffs])\n",
    "\n",
    "    use_models = [ref_model]\n",
    "\n",
    "    for i in range(N_models):\n",
    "        if i == ref_model:\n",
    "            continue\n",
    "        coeff_array = np.concatenate([coeff[i].flatten() for coeff in compare_coeffs])\n",
    "        rel_coeff_distance = np.abs(1 - (coeff_array / ref_coeff_array))\n",
    "        if np.max(rel_coeff_distance) < 10. * np.linalg.norm(q_bar[i] - q_bar[ref_model]):\n",
    "            use_models.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"linear_regime\":\n",
    "    # keep only the models that have z_rest > -10 mm\n",
    "    use_models = []\n",
    "    for i in range(N_models):\n",
    "        if metric[i] < 2.5: # q_bar[i][2] < -8 \n",
    "            use_models.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models == \"all\" or filter_models == \"only_default\":\n",
    "    use_models = list(range(N_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand-select models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 28\n",
    "# path = join(\"/media/jonas/Backup Plus/jonas_soft_robot_data/trunk_closed-loop_analysis/adiabatic_ssm_modified_idw_50/050\", f\"use_models_{index}.pkl\")\n",
    "# with open(path, \"rb\") as f:\n",
    "#     use_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_models = [34, 99, 2, 90, 84, 83, 6, 82, 81, 9, 10, 77, 75, 72, 70, 68, 61, 59, 55, 51, 20, 21, 1, 23, 48, 25, 26, 47, 28, 43, 30, 31, 32, 37, 49, 86, 19, 85, 35, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Number of used models: {len(use_models)}/{N_models}')\n",
    "# print(f\"USE_MODELS = {use_models}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the remaining grid points again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models != \"all\" and filter_models != \"only_default\":\n",
    "    # plt.close(\"all\")\n",
    "    fig = plt.figure()\n",
    "\n",
    "    R_linear_part = [r[:, :6] for r in r_coeff]\n",
    "    eigenvalues_real_part = [np.real(np.linalg.eigvals(r)) for r in R_linear_part]\n",
    "    metric = np.array([np.linalg.norm(eigenvalues, ord=-np.inf) for eigenvalues in eigenvalues_real_part])\n",
    "\n",
    "    if INTERPOLATE == \"xyz\" or INTERPOLATE == \"reduced_coords\":\n",
    "        ax = plt.axes(projection=\"3d\")\n",
    "        if color_by_metric:\n",
    "            sc = ax.scatter(psi_eq_array[use_models, 0], psi_eq_array[use_models, 1], psi_eq_array[use_models, 2], marker=\"o\", c=metric, vmax=None, cmap='viridis')\n",
    "        else:\n",
    "            not_use_models = np.ones(N_models, bool)\n",
    "            not_use_models[use_models] = 0\n",
    "            sc = ax.scatter(psi_eq_array[not_use_models, 0], psi_eq_array[not_use_models, 1], psi_eq_array[not_use_models, 2], marker=\"o\", color=\"darkblue\")\n",
    "            sc = ax.scatter(psi_eq_array[use_models, 0], psi_eq_array[use_models, 1], psi_eq_array[use_models, 2], marker=\"o\", color=\"tab:orange\")\n",
    "        for i in range(N_models):\n",
    "            ax.text(psi_eq_array[i, 0], psi_eq_array[i, 1], psi_eq_array[i, 2], str(i), size=10, zorder=1, color='k')\n",
    "        ax.set_zlabel(r\"$x_3$\")\n",
    "    else:\n",
    "        ax = plt.axes()\n",
    "        if INTERPOLATE == \"xy\":\n",
    "            color = \"tab:blue\"\n",
    "        elif INTERPOLATE == \"reduced_coords\":\n",
    "            color = \"tab:orange\"\n",
    "        if color_by_metric:\n",
    "            sc = ax.scatter(psi_eq_array[use_models, 0], psi_eq_array[use_models, 1], marker=\"o\", c=metric, vmax=None, cmap=\"viridis\")\n",
    "        else:\n",
    "            sc = ax.scatter(psi_eq_array[use_models, 0], psi_eq_array[use_models, 1], marker=\"o\", color=color)\n",
    "    if INTERPOLATE in  [\"xy\", \"xyz\"]:\n",
    "        ax.set_xlabel(r\"$x$ [mm]\")\n",
    "        ax.set_ylabel(r\"$y$ [mm]\")\n",
    "    elif INTERPOLATE == \"reduced_coords\":\n",
    "        ax.set_xlabel(r\"$x_1$\")\n",
    "        ax.set_ylabel(r\"$x_2$\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if color_by_metric:\n",
    "        plt.colorbar(sc, ax=ax, label=r\"$||Re(\\lambda)||_{\\infty}$\")\n",
    "        fig.suptitle(\"Slowest decay mode of the ROM's linear part\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all unused models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_models != \"all\" and filter_models != \"only_default\":\n",
    "    # only keep models in use_models\n",
    "    for i in range(N_models):\n",
    "        if i not in use_models:\n",
    "            V[i] = None\n",
    "            r_coeff[i] = None\n",
    "            w_coeff[i] = None\n",
    "            v_coeff[i] = None\n",
    "            B_r[i] = None\n",
    "            q_bar[i] = None\n",
    "            u_bar[i] = None\n",
    "            psi_eq[i] = None\n",
    "    V = [V[i] for i in range(len(V)) if V[i] is not None]\n",
    "    r_coeff = [r_coeff[i] for i in range(len(r_coeff)) if r_coeff[i] is not None]\n",
    "    w_coeff = [w_coeff[i] for i in range(len(w_coeff)) if w_coeff[i] is not None]\n",
    "    v_coeff = [v_coeff[i] for i in range(len(v_coeff)) if v_coeff[i] is not None]\n",
    "    B_r = [B_r[i] for i in range(len(B_r)) if B_r[i] is not None]\n",
    "    q_bar = [q_bar[i] for i in range(len(q_bar)) if q_bar[i] is not None]\n",
    "    u_bar = [u_bar[i] for i in range(len(u_bar)) if u_bar[i] is not None]\n",
    "    psi_eq = [psi_eq[i] for i in range(len(psi_eq)) if psi_eq[i] is not None]\n",
    "    N_models = len(V)\n",
    "    print(f'N_models: {N_models}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test trajectory (for now: sum of all trajectories used to regress B matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 20001)\n"
     ]
    }
   ],
   "source": [
    "# test_trajectory_dir = \"open-loop\"\n",
    "test_trajectories = []\n",
    "# for name in tqdm(model_names): # ['origin']: # \n",
    "traj_dir = \"/home/jonas/Projects/stanford/soft-robot-control/examples/trunk/dataCollection/open-loop_500\" # join(model_dir, name, test_trajectory_dir)\n",
    "(t, z), u = utils.import_pos_data(data_dir=traj_dir,\n",
    "                                  rest_file=rest_file,\n",
    "                                  output_node=TIP_NODE, return_inputs=True, traj_index=0)\n",
    "y = assemble_observables(z)\n",
    "print(y.shape)\n",
    "test_trajectories.append({\n",
    "        'name': split(traj_dir)[-1],\n",
    "        't': t,\n",
    "        'z': z,\n",
    "        'u': u,\n",
    "        'y': y\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine into one long trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tot = np.hstack([traj['z'] for traj in test_trajectories])\n",
    "y_tot = np.hstack([traj['y'] for traj in test_trajectories])\n",
    "u_tot = np.hstack([traj['u'] for traj in test_trajectories])\n",
    "t_tot = np.arange(z_tot.shape[1]) * DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.45404214  1.45404214  1.45404214  1.45404214  1.45404214  2.33910265  3.80858391]\n",
      " [-0.30603326 -0.30603326 -0.30603326 -0.30603326 -0.30603326  0.22956691  1.0630584 ]\n",
      " [-0.61577293 -0.61577293 -0.61577293 -0.61577293 -0.61577293 -1.12924379 -1.68801492]\n",
      " [ 1.45404214  1.45404214  1.45404214  1.45404214  2.33910265  3.80858391  5.76772698]\n",
      " [-0.30603326 -0.30603326 -0.30603326 -0.30603326  0.22956691  1.0630584   2.08882514]\n",
      " [-0.61577293 -0.61577293 -0.61577293 -0.61577293 -1.12924379 -1.68801492 -2.29402946]\n",
      " [ 1.45404214  1.45404214  1.45404214  2.33910265  3.80858391  5.76772698  8.14045726]\n",
      " [-0.30603326 -0.30603326 -0.30603326  0.22956691  1.0630584   2.08882514  3.22522734]\n",
      " [-0.61577293 -0.61577293 -0.61577293 -1.12924379 -1.68801492 -2.29402946 -2.96579944]\n",
      " [ 1.45404214  1.45404214  2.33910265  3.80858391  5.76772698  8.14045726 10.85347754]\n",
      " [-0.30603326 -0.30603326  0.22956691  1.0630584   2.08882514  3.22522734  4.40423198]\n",
      " [-0.61577293 -0.61577293 -1.12924379 -1.68801492 -2.29402946 -2.96579944 -3.71819864]\n",
      " [ 1.45404214  2.33910265  3.80858391  5.76772698  8.14045726 10.85347754 13.83519461]\n",
      " [-0.30603326  0.22956691  1.0630584   2.08882514  3.22522734  4.40423198  5.56927416]\n",
      " [-0.61577293 -1.12924379 -1.68801492 -2.29402946 -2.96579944 -3.71819864 -4.56011012]]\n",
      "[[ 1.45404214  2.33910265  3.80858391  5.76772698  8.14045726 10.85347754 13.83519461]\n",
      " [-0.30603326  0.22956691  1.0630584   2.08882514  3.22522734  4.40423198  5.56927416]\n",
      " [-0.61577293 -1.12924379 -1.68801492 -2.29402946 -2.96579944 -3.71819864 -4.56011012]]\n"
     ]
    }
   ],
   "source": [
    "print(y_tot[:, :7])\n",
    "print(z_tot[:, :7])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate local models to obtain adiabatic SSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_methods = [\"modified_idw\", \"qp\", \"nn\", \"linear\", \"ct\"]\n",
    "coeff_dict = {\n",
    "            'w_coeff': w_coeff,\n",
    "            'V': V,\n",
    "            'r_coeff': r_coeff,\n",
    "            'B_r': B_r,\n",
    "            'u_bar': u_bar,\n",
    "        }\n",
    "# if INTERPOLATE in [\"xyz\", \"xy\"]:\n",
    "coeff_dict['q_bar'] = q_bar\n",
    "if INTERPOLATE == \"reduced_coords\":\n",
    "    coeff_dict['x_bar'] = [V[i].T @ np.tile(q_bar[i], 5) for i in range(len(q_bar))]\n",
    "\n",
    "interpolators = {}\n",
    "for interpolation_method in interpolation_methods:\n",
    "    if interpolation_method in [\"qp\", \"linear\", \"ct\"]:\n",
    "        interp_slice = np.s_[:2]\n",
    "    else:\n",
    "        interp_slice = np.s_[:]\n",
    "    interpolators[interpolation_method] = InterpolatorFactory(interpolation_method, [psi_eq[interp_slice] for psi_eq in psi_eq], coeff_dict).get_interpolator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_names = {\n",
    "    \"origin_only\": \"Origin model\",\n",
    "    \"nn\": \"Nearest neighbor\",\n",
    "    \"linear\": \"Barycentric linear\",\n",
    "    \"ct\": \"Clough-Tocher\",\n",
    "    \"idw\": \"Inverse distance weighting\",\n",
    "    \"modified_idw\": \"Modified IDW\",\n",
    "    \"qp\": \"Quadratic polynomial regression\",\n",
    "    \"natural_neighbor\": \"Natural neighbor\",\n",
    "    \"koopman\": \"Koopman\",\n",
    "    \"tpwl\": \"TPWL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize interpolation landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERPOLATE in [\"xy\", \"reduced_coords\"]:\n",
    "    nx, ny = (500, 500)\n",
    "    x = np.linspace(-50, 50, nx)\n",
    "    y = np.linspace(-50, 50, ny)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    # xy = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "    coeff = \"r_coeff\"\n",
    "    entry = np.s_[0, 0]\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    z = {}\n",
    "    # grad_norm = {}\n",
    "\n",
    "    for interpolation_method in interpolation_methods:\n",
    "        print(f\"======== {interpolation_method} =========\")\n",
    "        z[interpolation_method] = np.zeros((nx, ny))\n",
    "        if interpolation_method in [\"qp\", \"linear\", \"ct\"]:\n",
    "            interp_slice = np.s_[:2]\n",
    "        else:\n",
    "            interp_slice = np.s_[:]\n",
    "        for i in tqdm(range(nx)):\n",
    "            for j in range(ny):\n",
    "                if INTERPOLATE == \"xy\":\n",
    "                    psi = [xv[i, j], yv[i, j]]\n",
    "                elif INTERPOLATE == \"reduced_coords\":\n",
    "                    psi = np.zeros(6)\n",
    "                    psi[0:2] = [xv[i, j], yv[i, j]]\n",
    "                else:\n",
    "                    psi = None\n",
    "                z[interpolation_method][i, j] = interpolators[interpolation_method].transform(psi[interp_slice], coeff)[entry]\n",
    "        # gx, gy = np.gradient(z[interpolation_method], x, y)\n",
    "        # grad_norm[interpolation_method] = np.sqrt(gx**2 + gy**2)\n",
    "        # print(f\"Maximum gradient norm: {np.nanmax(grad_norm[interpolation_method]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERPOLATE in [\"xy\", \"reduced_coords\"]:\n",
    "    plt.close(\"all\")\n",
    "    fig1, axs1 = plt.subplots(1, len(interpolation_methods), figsize=(15, 4), subplot_kw={\"projection\": \"3d\"})\n",
    "    fig2, axs2 = plt.subplots(1, len(interpolation_methods), figsize=(15, 4), sharey=True)\n",
    "\n",
    "    vmin, vmax = -3.14, -3.08\n",
    "\n",
    "    for i, interpolation_method in enumerate(interpolation_methods):\n",
    "        ax1 = axs1[i]\n",
    "        ax1.plot_surface(xv, yv, z[interpolation_method], cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "        # xi, yi, zi = psi_eq_array[:, 0], psi_eq_array[:, 1], np.array([r[entry] for r in r_coeff])\n",
    "        # xi, yi, zi = xi[((np.abs(xi) < 50) & (np.abs(yi) < 50))], yi[((np.abs(xi) < 50) & (np.abs(yi) < 50))], zi[((np.abs(xi) < 50) & (np.abs(yi) < 50))]\n",
    "        # ax1.plot(xi, yi, zi, color=\"tab:blue\", ls=\"\", marker=\"o\", markersize=12, alpha=1)\n",
    "        ax1.set_xlabel(r\"$x_1$\")\n",
    "        ax1.set_ylabel(r\"$x_2$\")\n",
    "        ax1.set_zlabel(r\"$R[0, 0]$\")\n",
    "        ax1.set_zlim(vmin, vmax)\n",
    "        # ax.view_init(90, -90)\n",
    "        ax1.set_title(display_names[interpolation_method])\n",
    "        ax1.set_zticks([])\n",
    "        ax1.set_zticklabels([])\n",
    "        ax1.set_box_aspect((1, 1, 0.7))\n",
    "        ax1.set_xlim(-50, 50)\n",
    "        ax1.set_ylim(-50, 50)\n",
    "        ax2 = axs2[i]\n",
    "        im = ax2.contourf(xv, yv, z[interpolation_method], cmap=\"viridis\", levels=20, vmin=vmin, vmax=vmax)\n",
    "        ax2.plot(psi_eq_array[:, 0], psi_eq_array[:, 1], color=\"white\", ls=\"\", marker=\"o\", markersize=3, alpha=1)\n",
    "        ax2.set_xlabel(r\"$x_1$\")\n",
    "        ax2.set_aspect(\"equal\")\n",
    "        ax2.set_xlim(-50, 50)\n",
    "        ax2.set_ylim(-50, 50)\n",
    "    axs2[0].set_ylabel(r\"$x_2$\")    \n",
    "    # fig2.colorbar(im, ax=axs2.ravel().tolist(), shrink=.95, pad=0.02, fraction=1, label=r\"$R[0, 0]$\")\n",
    "\n",
    "        # ax2 = axs2[i]\n",
    "        # im = ax2.imshow(grad_norm[interpolation_method], cmap=\"viridis\", vmin=0, vmax=.1)\n",
    "\n",
    "        # ax2.set_title(display_names[interpolation_method])\n",
    "        # ax2.set_xticks([])\n",
    "        # ax2.set_yticks([])\n",
    "    # plt.colorbar(im, ax=axs2.ravel().tolist(), shrink=.95, pad=0.02, fraction=1, label=\"Gradient norm\")\n",
    "    fig1.savefig(join(traj_dir, f\"interpolation_landscapes_3d.png\"), bbox_inches='tight', dpi=300)\n",
    "    fig2.savefig(join(traj_dir, f\"interpolation_landscapes_2d-contour.png\"), bbox_inches='tight', dpi=300)\n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample finite-horizon predictions to evaluate interpolated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_horizon = 5\n",
    "N_samples = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20001)\n"
     ]
    }
   ],
   "source": [
    "print(z_tot.shape)\n",
    "np.random.seed(seed=1)\n",
    "sample_indices = randint(0, z_tot.shape[1], N_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb5252c45cc40a0a4698fa292867ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== modified_idw ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ce814bb81b4bc492e54e9c08caf082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg RMSE: 0.720862165797345\n",
      "==================== qp ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82846d91c364b4b892dd09779a302f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg RMSE: 0.9533232826199679\n",
      "==================== nn ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078096ab138d4a1ea620794e870c5768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg RMSE: 0.8785582443994367\n",
      "==================== linear ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d0c0b822d3420facb88738fbf69b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg RMSE: 0.7171938572013488\n",
      "==================== ct ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5747a607abf410185c7c67d7d031c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg RMSE: 0.7970956867639717\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "z_preds = {}\n",
    "rmse_samples = {}\n",
    "xdots = {}\n",
    "\n",
    "for interpolation_method in tqdm(interpolation_methods, position=0):\n",
    "    print(f\"==================== {interpolation_method} ====================\")\n",
    "    q_samples = []\n",
    "    rmse_samples[interpolation_method] = []\n",
    "    xdots[interpolation_method] = []\n",
    "    advect_times = []\n",
    "    z_preds[interpolation_method] = []\n",
    "    z_trues = []\n",
    "\n",
    "    if interpolation_method == \"qp\":\n",
    "        interp_slice = np.s_[:2]\n",
    "    elif interpolation_method in [\"linear\", \"ct\"]:\n",
    "        interp_slice = np.s_[:2]\n",
    "    else:\n",
    "        interp_slice = None\n",
    "\n",
    "    for i in tqdm(range(N_samples), position=1, leave=True):\n",
    "        try:\n",
    "            start_idx = sample_indices[i]\n",
    "            end_idx = start_idx + N_horizon\n",
    "            q_samples.append(z_tot[:3, start_idx])\n",
    "            # advect ASSM to obtain finite-horizon prediction\n",
    "            t0 = time.time()\n",
    "            t, _, y_pred, xdot, _, _, _ = utils.advect_adiabaticRD_with_inputs(t_tot[start_idx:end_idx], y_tot[:, start_idx], u_tot[:, start_idx:end_idx],\n",
    "                                                                            y_target=y_tot[:, start_idx:end_idx], interpolate=INTERPOLATE, interp_slice=interp_slice,\n",
    "                                                                            interpolator=interpolators[interpolation_method],\n",
    "                                                                            ROMOrder=ROMOrder, know_target=False)\n",
    "            t1 = time.time()\n",
    "            # compute RMSE\n",
    "            z_pred, z_true = y_pred[-3:, :], y_tot[-3:, start_idx:end_idx]\n",
    "            rmse = np.sqrt(np.mean(np.linalg.norm(z_pred - z_true, axis=0)**2))\n",
    "            rmse_samples[interpolation_method].append(rmse)\n",
    "            advect_times.append(t1 - t0)\n",
    "            z_preds[interpolation_method].append(z_pred)\n",
    "            z_trues.append(z_true)\n",
    "            xdots[interpolation_method].append(xdot)\n",
    "        except:\n",
    "            # RMSE is nan\n",
    "            rmse_samples[interpolation_method].append(np.nan)\n",
    "            advect_times.append(np.nan)\n",
    "            z_preds[interpolation_method].append(np.full((3, N_horizon), np.nan))\n",
    "            z_trues.append(np.full((3, N_horizon), np.nan))\n",
    "            xdots[interpolation_method].append(np.full((6, N_horizon), np.nan))\n",
    "        \n",
    "    # max_rmse_index = np.argmax(rmse_samples)\n",
    "    print(\"avg RMSE:\", np.nanmean(rmse_samples[interpolation_method]))\n",
    "    # print(\"max RMSE sample idx:\", sample_indices[max_rmse_index])\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_n=9_rmse_samples.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(rmse_samples[interpolation_method], f)\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_n=9_q_samples.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(q_samples, f)\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_n=9_advect_times.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(advect_times, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the random ground-truth trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.predicted_trajectories(np.zeros(z_tot.shape[0]), z_tot, N_samples * [np.full((3, N_horizon), np.nan)], N_samples * [np.full((3, N_horizon), np.nan)], save_path=\"predicted_trajectories_ground-truth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the best and worst predicted trajectories, branching out from random input trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plot.predicted_trajectories(rmse_samples[\"origin_only\"], z_tot, z_preds[\"origin_only\"], z_trues, save_path=\"predicted_trajectories_origin_only\")\n",
    "plot.predicted_trajectories(rmse_samples[\"modified_idw\"], z_tot, z_preds[\"modified_idw\"], z_trues, save_path=\"predicted_trajectories_modified_idw\")\n",
    "plot.predicted_trajectories(rmse_samples[\"qp\"], z_tot, z_preds[\"qp\"], z_trues, save_path=\"predicted_trajectories_qp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate prediction accuracy for baselines: Koopman, TPWL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koopman"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Koopman model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sofacontrol.baselines.koopman import koopman_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koopman_data = loadmat(\"/home/jonas/Projects/stanford/soft-robot-control/examples/trunk/koopman_model.mat\")['py_data'][0, 0]\n",
    "raw_model = koopman_data['model']\n",
    "raw_params = koopman_data['params']\n",
    "model = koopman_utils.KoopmanModel(raw_model, raw_params)\n",
    "scaling = koopman_utils.KoopmanScaling(scale=model.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.A_d.shape\n",
    "# model.B_d.shape\n",
    "# model.V.shape\n",
    "# model.W.shape\n",
    "# model.state_dim\n",
    "# model.C.shape\n",
    "# zeta_test = np.ones(14)\n",
    "# lifted_zeta_test = model.lift_data(*zeta_test)\n",
    "# model.B_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advect Koopman model and evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tot_koopman = (z_tot.T + rest_q[3*TIP_NODE:3*(TIP_NODE+1)]).T\n",
    "z_tot_koopman = scaling.scale_down(y=z_tot_koopman.T).T\n",
    "u_tot_koopman = scaling.scale_down(u=utils.delayEmbedding(u_tot, up_to_delay=1, embed_coords=list(range(8)))[:8, :].T).T\n",
    "y_tot_koopman = np.vstack([z_tot_koopman, utils.delayEmbedding(z_tot_koopman, up_to_delay=1)[:3, :], u_tot_koopman])\n",
    "\n",
    "rmse_samples = []\n",
    "xdots = []\n",
    "advect_times = []\n",
    "z_preds = []\n",
    "z_trues = []\n",
    "q_samples = []\n",
    "\n",
    "for i in tqdm(range(N_samples), position=1, leave=True):\n",
    "    start_idx = sample_indices[i]\n",
    "    end_idx = start_idx + N_horizon\n",
    "    q_samples.append(z_tot[:3, start_idx])\n",
    "    t0 = time.time()\n",
    "    # advect Koopman to obtain finite-horizon prediction\n",
    "    t, y, u = t_tot[start_idx:end_idx], y_tot_koopman[:, start_idx:end_idx], u_tot_koopman[:, start_idx:end_idx]\n",
    "    y0 = y[:, 0]\n",
    "    N = len(t)-1\n",
    "    x = np.full((model.A_d.shape[0], N+1), np.nan)\n",
    "    xdot = np.full((model.A_d.shape[0], N), np.nan)\n",
    "    y_pred = np.full((len(y0), N+1), np.nan)\n",
    "    y_pred[:, 0] = y0\n",
    "    # advect for horizon N\n",
    "    for i in range(N):\n",
    "        # lift the observables\n",
    "        if i == 0:\n",
    "            x[:, i] = model.lift_data(*y_pred[:, i])\n",
    "        # compute the Koopman prediction\n",
    "        # xdot[:, i]\n",
    "        x[:, i+1] = model.A_d @ x[:, i] + model.B_d @ u[:, i]\n",
    "        # forward Euler: x[i+1] = x[i] + dt * xdot[i]\n",
    "        # x[:, i+1] = x[:, i] + DT * xdot[:, i]\n",
    "        y_pred[:, i+1] = np.concatenate([model.C @ x[:, i+1], y_pred[:3, i], u[:, i]])\n",
    "    t1 = time.time()\n",
    "    # compute RMSE\n",
    "    z_pred = (scaling.scale_up(y=y_pred[:3, :].T) - rest_q[3*TIP_NODE:3*(TIP_NODE+1)]).T\n",
    "    z_true = z_tot[:, start_idx:end_idx]\n",
    "    rmse = np.sqrt(np.mean(np.linalg.norm(z_pred - z_true, axis=0)**2))\n",
    "    rmse_samples.append(rmse)\n",
    "    advect_times.append(t1 - t0)\n",
    "    z_preds.append(z_pred)\n",
    "    z_trues.append(z_true)\n",
    "    xdots.append(xdot)\n",
    "\n",
    "print(\"avg RMSE:\", np.nanmean(rmse_samples))\n",
    "# print(\"max RMSE sample idx:\", sample_indices[max_rmse_index])\n",
    "with open(join(traj_dir, f\"koopman_rmse_samples.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(rmse_samples, f)\n",
    "with open(join(traj_dir, f\"koopman_q_samples.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(q_samples, f)\n",
    "with open(join(traj_dir, f\"koopman_advect_times.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(advect_times, f)\n",
    "\n",
    "print(rmse_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.predicted_trajectories(rmse_samples, z_tot, z_preds, z_trues, save_path=\"predicted_trajectories_koopman\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPWL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TPWL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sofacontrol.tpwl import tpwl, tpwl_config\n",
    "from sofacontrol.measurement_models import linearModel, MeasurementModel\n",
    "\n",
    "# Specify a measurement and output model\n",
    "cov_q = 0.0 * np.eye(3 * len([TIP_NODE]))\n",
    "cov_v = 0.0 * np.eye(3 * len([TIP_NODE]))\n",
    "measurement_model = linearModel(nodes=[TIP_NODE], num_nodes=N_NODES)\n",
    "output_model = MeasurementModel(nodes=[TIP_NODE], num_nodes=N_NODES, pos=True, vel=True, S_q=cov_q, S_v=cov_v)\n",
    "# Load and configure the TPWL model from data saved\n",
    "tpwl_model_file = \"/home/jonas/Projects/stanford/soft-robot-control/examples/trunk/tpwl_model_snapshots.pkl\"\n",
    "config = tpwl_config.tpwl_dynamics_config()\n",
    "model = tpwl.TPWLATV(data=tpwl_model_file, params=config.constants_sim, Hf=output_model.C,\n",
    "                     Cf=measurement_model.C)\n",
    "model.pre_discretize(dt=DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measurement_model.C.shape)\n",
    "print(model.C.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import trajectories (pos and vel) of all FEM nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_trajectory_dir = \"open-loop\"\n",
    "test_trajectories = []\n",
    "# for name in tqdm(model_names): # ['origin']: # \n",
    "traj_dir = \"/home/jonas/Projects/stanford/soft-robot-control/examples/trunk/dataCollection/open-loop_500\" # join(model_dir, name, test_trajectory_dir)\n",
    "(t, qv), u = utils.import_pos_data(data_dir=traj_dir,\n",
    "                                  rest_file=rest_file,\n",
    "                                  output_node=\"all\", return_inputs=True, return_velocity=True, traj_index=0)\n",
    "\n",
    "test_trajectories.append({\n",
    "        'name': split(traj_dir)[-1],\n",
    "        't': t,\n",
    "        'q': qv[:3*N_NODES, :],\n",
    "        'v': qv[3*N_NODES:, :],\n",
    "        'u': u,\n",
    "    })\n",
    "\n",
    "q_tot = np.hstack([traj['q'] for traj in test_trajectories])\n",
    "v_tot = np.hstack([traj['v'] for traj in test_trajectories])\n",
    "u_tot = np.hstack([traj['u'] for traj in test_trajectories])\n",
    "t_tot = np.arange(z_tot.shape[1]) * DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"q_tot.shape:\", q_tot.shape)\n",
    "print(\"v_tot.shape:\", v_tot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advect TWPL model and evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.H.shape)\n",
    "print(model.C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_samples = []\n",
    "xdots = []\n",
    "advect_times = []\n",
    "z_preds = []\n",
    "z_true = []\n",
    "q_samples = []\n",
    "\n",
    "for j in tqdm(range(N_samples), position=1, leave=True):\n",
    "    start_idx = sample_indices[j]\n",
    "    end_idx = start_idx + N_horizon\n",
    "    q_samples.append(z_tot[:3, start_idx])\n",
    "    t0 = time.time()\n",
    "    t, q, v, u = t_tot[start_idx:end_idx], q_tot[:, start_idx:end_idx], v_tot[:, start_idx:end_idx], u_tot[:, start_idx:end_idx]\n",
    "    N = len(t)-1\n",
    "    xf = np.vstack([v, q]) + model.rom.x_ref[:, None]\n",
    "    # print(xf.shape)\n",
    "    x0 = model.rom.compute_RO_state(xf=xf[:, 0])\n",
    "    x = np.full((model.state_dim, N+1), np.nan)\n",
    "    xdot = np.full((model.state_dim, N), np.nan)\n",
    "    x[:, 0] = x0\n",
    "    z0 = model.x_to_zy(x0, z=True)\n",
    "    # print(z0)\n",
    "    # print(z_tot[:, start_idx])\n",
    "    # advect for horizon N\n",
    "    for i in range(N):\n",
    "        # compute the TPWL prediction\n",
    "        A, B, d = model.get_jacobians(x=x[:, i], u=u[:, i], dt=DT)\n",
    "        # xdot[i] = R(x[i]) + B[i] @ (u[i] - u_bar[i])\n",
    "        # xdot[:, i] = A @ x[:, i] + B @ u[:, i] + d\n",
    "        # print(np.linalg.eig(A))\n",
    "        # forward Euler: x[i+1] = x[i] + dt * xdot[i]\n",
    "        x[:, i+1] = A @ x[:, i] + B @ u[:, i] + d\n",
    "        # x[:, i+1] = x[:, i] + DT * xdot[:, i]\n",
    "    t1 = time.time()\n",
    "    # compute RMSE\n",
    "    z_pred = model.x_to_zy(x.T, z=True).T[3:, :]\n",
    "    z_true = z_tot[:, start_idx:end_idx]\n",
    "    # print(z_pred.shape)\n",
    "    # print(z_true.shape)\n",
    "    rmse = np.sqrt(np.mean(np.linalg.norm(z_pred - z_true, axis=0)**2))\n",
    "    rmse_samples.append(rmse)\n",
    "    advect_times.append(t1 - t0)\n",
    "    z_preds.append(z_pred)\n",
    "    z_trues.append(z_true)\n",
    "    xdots.append(xdot)\n",
    "\n",
    "print(\"avg RMSE:\", np.nanmean(rmse_samples))\n",
    "print(\"min RMSE:\", np.nanmin(rmse_samples), \"max RMSE:\", np.nanmax(rmse_samples))\n",
    "# print(\"max RMSE sample idx:\", sample_indices[max_rmse_index])\n",
    "with open(join(traj_dir, f\"tpwl_rmse_samples.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(rmse_samples, f)\n",
    "with open(join(traj_dir, f\"tpwl_q_samples.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(q_samples, f)\n",
    "with open(join(traj_dir, f\"tpwl_advect_times.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(advect_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.predicted_trajectories(rmse_samples, z_tot, z_preds, z_trues, save_path=\"predicted_trajectories_tpwl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prediction accuracy maps for all the different interpolation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "interpolation_methods = [\"linear\", \"ct\", \"ct_n=9\"] # [\"modified_idw\", \"qp\", \"nn\"] # \n",
    "baselines = []\n",
    "methods = interpolation_methods + baselines\n",
    "\n",
    "display_names_all_adiabatic = copy.copy(display_names)\n",
    "display_names_all_adiabatic[\"ct\"] = r\"Clough-Tocher ($N_{grid}=109$)\"\n",
    "display_names_all_adiabatic[\"ct_n=9\"] = r\"Clough-Tocher ($N_{grid}=9$)\"\n",
    "\n",
    "show_advect_times = False\n",
    "\n",
    "fig, axs = plt.subplots(3 + show_advect_times, len(methods),\n",
    "                        figsize=(4*len(methods), (12 if show_advect_times else 10)),\n",
    "                        height_ratios=([4, 3, 2, 2] if show_advect_times else [5, 2, 1]),\n",
    "                        sharey='row', sharex='row', layout=\"compressed\")\n",
    "for i, method in enumerate(methods):\n",
    "    with open(join(traj_dir, f\"{method}_rmse_samples.pkl\"), \"rb\") as f:\n",
    "        rmse_samples = np.array(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_q_samples.pkl\"), \"rb\") as f:\n",
    "        q_samples = np.stack(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_advect_times.pkl\"), \"rb\") as f:\n",
    "        advect_times = np.array(pickle.load(f))\n",
    "    colorbar = (i == len(methods) - 1)\n",
    "    if i == 0:\n",
    "        ylabels = [r\"$y$ [mm]\", r\"$z$ [mm]\"]\n",
    "    else:\n",
    "        ylabels = [\"\", \"\"]\n",
    "    plot.prediction_accuracy_map(q_samples[:, [0, 1]], rmse_samples, vmin=0., vmax=4., ax=axs[0, i], colorbar=colorbar, ylabel=ylabels[0], cax=axs[:, :], show=False)\n",
    "    plot.prediction_accuracy_map(np.array([q_samples[:, 0], -q_samples[:, 2]]).T, rmse_samples, vmin=0., vmax=4., ax=axs[1, i], colorbar=False, ylabel=ylabels[1], cax=axs[:, :], show=False)\n",
    "    plot.boxplot(rmse_samples, ax=axs[2, i], show=False, xlabel=\"RMSE [mm]\")\n",
    "    if show_advect_times:\n",
    "        plot.boxplot(advect_times, ax=axs[2, i], show=False, xlabel=\"Advect time [s]\")\n",
    "    axs[0, i].set_title(display_names_all_adiabatic[method])\n",
    "    # if i > 0:\n",
    "    #     axs[0, i].set_ylabel(\"\")\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_all-adiabatic-B.png\"), bbox_inches='tight', dpi=300)\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_all-adiabatic-B.eps\"), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_methods = [\"modified_idw\", \"origin_only\"]\n",
    "baselines = [\"tpwl\"]\n",
    "methods = interpolation_methods + baselines\n",
    "\n",
    "show_advect_times = False\n",
    "\n",
    "fig, axs = plt.subplots(3 + show_advect_times, len(methods),\n",
    "                        figsize=(4*len(methods), (12 if show_advect_times else 10)),\n",
    "                        height_ratios=([4, 3, 2, 2] if show_advect_times else [5, 2, 1]),\n",
    "                        sharey='row', sharex='row', layout=\"compressed\")\n",
    "for i, method in enumerate(methods):\n",
    "    with open(join(traj_dir, f\"{method}_rmse_samples.pkl\"), \"rb\") as f:\n",
    "        rmse_samples = np.array(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_q_samples.pkl\"), \"rb\") as f:\n",
    "        q_samples = np.stack(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_advect_times.pkl\"), \"rb\") as f:\n",
    "        advect_times = np.array(pickle.load(f))\n",
    "    colorbar = (i == len(methods) - 1)\n",
    "    if i == 0:\n",
    "        ylabels = [r\"$y$ [mm]\", r\"$z$ [mm]\"]\n",
    "    else:\n",
    "        ylabels = [\"\", \"\"]\n",
    "    plot.prediction_accuracy_map(q_samples[:, [0, 1]], rmse_samples, vmin=0., vmax=4., ax=axs[0, i], colorbar=colorbar, ylabel=ylabels[0], cax=axs[:, :], show=False)\n",
    "    plot.prediction_accuracy_map(np.array([q_samples[:, 0], -q_samples[:, 2]]).T, rmse_samples, vmin=0., vmax=4., ax=axs[1, i], colorbar=False, ylabel=ylabels[1], cax=axs[:, :], show=False)\n",
    "    plot.boxplot(rmse_samples, ax=axs[2, i], show=False, xlabel=\"RMSE [mm]\")\n",
    "    if show_advect_times:\n",
    "        plot.boxplot(advect_times, ax=axs[2, i], show=False, xlabel=\"Advect time [s]\")\n",
    "    axs[0, i].set_title(display_names[method])\n",
    "    # if i > 0:\n",
    "    #     axs[0, i].set_ylabel(\"\")\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy.png\"), bbox_inches='tight', dpi=300)\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy.eps\"), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_methods = [\"modified_idw\", \"origin_only\", ] # [\"origin_only\", \"idw\", \"modified_idw\"] # , \"qp\"] # [\"origin_only\", \"linear\", \"nn\", \"qp\"] # , \"tps\", \"ls\", \"qp\"]\n",
    "baselines = [\"koopman\"]\n",
    "methods = interpolation_methods + baselines\n",
    "\n",
    "show_advect_times = False\n",
    "\n",
    "fig, axs = plt.subplots(3 + show_advect_times, len(methods),\n",
    "                        figsize=(4*len(methods), (12 if show_advect_times else 10)),\n",
    "                        height_ratios=([4, 3, 2, 2] if show_advect_times else [5, 2, 1]),\n",
    "                        sharey='row', sharex='row', layout=\"compressed\")\n",
    "for i, method in enumerate(methods):\n",
    "    with open(join(traj_dir, f\"{method}_rmse_samples.pkl\"), \"rb\") as f:\n",
    "        rmse_samples = np.array(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_q_samples.pkl\"), \"rb\") as f:\n",
    "        q_samples = np.stack(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_advect_times.pkl\"), \"rb\") as f:\n",
    "        advect_times = np.array(pickle.load(f))\n",
    "    colorbar = (i == len(methods) - 1)\n",
    "    if i == 0:\n",
    "        ylabels = [r\"$y$ [mm]\", r\"$z$ [mm]\"]\n",
    "    else:\n",
    "        ylabels = [\"\", \"\"]\n",
    "    plot.prediction_accuracy_map(q_samples[:, [0, 1]], rmse_samples, vmin=0., vmax=50., ax=axs[0, i], colorbar=colorbar, ylabel=ylabels[0], cax=axs[:, :], show=False) # 4.\n",
    "    plot.prediction_accuracy_map(np.array([q_samples[:, 0], -q_samples[:, 2]]).T, rmse_samples, vmin=0., vmax=50., ax=axs[1, i], colorbar=False, ylabel=ylabels[1], cax=axs[:, :], show=False) # 4.\n",
    "    plot.boxplot(rmse_samples, ax=axs[2, i], show=False, xlabel=\"RMSE [mm]\")\n",
    "    if show_advect_times:\n",
    "        plot.boxplot(advect_times, ax=axs[2, i], show=False, xlabel=\"Advect time [s]\")\n",
    "    axs[0, i].set_title(display_names[method])\n",
    "    # if i > 0:\n",
    "    #     axs[0, i].set_ylabel(\"\")\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_ssm_and_koopman.png\"), bbox_inches='tight', dpi=300)\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_ssm_and_koopman.eps\"), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_methods = []\n",
    "baselines = [\"koopman\"]\n",
    "methods = interpolation_methods + baselines\n",
    "\n",
    "show_advect_times = False\n",
    "\n",
    "fig, axs = plt.subplots(3 + show_advect_times, len(methods),\n",
    "                        figsize=(4*len(methods), (12 if show_advect_times else 10)),\n",
    "                        height_ratios=([4, 3, 2, 2] if show_advect_times else [5, 2, 1]),\n",
    "                        sharey='row', sharex='row', layout=\"compressed\")\n",
    "axs = np.atleast_2d(axs).T\n",
    "for i, method in enumerate(methods):\n",
    "    with open(join(traj_dir, f\"{method}_rmse_samples.pkl\"), \"rb\") as f:\n",
    "        rmse_samples = np.array(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_q_samples.pkl\"), \"rb\") as f:\n",
    "        q_samples = np.stack(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{method}_advect_times.pkl\"), \"rb\") as f:\n",
    "        advect_times = np.array(pickle.load(f))\n",
    "    colorbar = (i == len(methods) - 1)\n",
    "    if i == 0:\n",
    "        ylabels = [r\"$y$ [mm]\", r\"$z$ [mm]\"]\n",
    "    else:\n",
    "        ylabels = [\"\", \"\"]\n",
    "    plot.prediction_accuracy_map(q_samples[:, [0, 1]], rmse_samples, vmin=0., vmax=50., ax=axs[0, i], colorbar=colorbar, ylabel=ylabels[0], cax=axs[:, :], show=False)\n",
    "    plot.prediction_accuracy_map(np.array([q_samples[:, 0], -q_samples[:, 2]]).T, rmse_samples, vmin=0., vmax=50., ax=axs[1, i], colorbar=False, ylabel=ylabels[1], cax=axs[:, :], show=False)\n",
    "    plot.boxplot(rmse_samples, ax=axs[2, i], show=False, xlabel=\"RMSE [mm]\")\n",
    "    if show_advect_times:\n",
    "        plot.boxplot(advect_times, ax=axs[2, i], show=False, xlabel=\"Advect time [s]\")\n",
    "    axs[0, i].set_title(display_names[method])\n",
    "    # if i > 0:\n",
    "    #     axs[0, i].set_ylabel(\"\")\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_koopman.png\"), bbox_inches='tight', dpi=300)\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy_koopman.eps\"), bbox_inches='tight', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
