{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiabatic SSM model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying prediction accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook quantifies the prediction of adiabatic SSM models by doing finite-horizon predictions across the robot's workspace and evaluating the corresponding prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, split, isdir\n",
    "import pickle\n",
    "import yaml\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import yaml\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils as utils\n",
    "import plot_utils as plot\n",
    "from interpolators import InterpolatorFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiabatic SSM settings\n",
    "ROMOrder = 3\n",
    "# N_samples = 100\n",
    "DT = 0.01\n",
    "INTERPOLATE_3D = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trunk settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = \"delay-embedding\" # \"delay-embedding\" # \"pos-vel\" # \n",
    "N_DELAY = 4 # only relevant if observables is \"delay-embedding\"\n",
    "TIP_NODE = 51\n",
    "N_NODES = 709\n",
    "INPUT_DIM = 8\n",
    "DT = 0.01\n",
    "\n",
    "rDOF = 3\n",
    "oDOF = 3\n",
    "SSMDim = 6\n",
    "\n",
    "robot_dir = \"../../../soft-robot-control/examples/trunk\"\n",
    "rest_file = join(robot_dir, 'rest_qv.pkl')\n",
    "\n",
    "# load rest position\n",
    "with open(rest_file, 'rb') as f:\n",
    "    rest_data = pickle.load(f)\n",
    "    rest_q = rest_data['q'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/media/jonas/Backup Plus/jonas_soft_robot_data/trunk_adiabatic_10ms_N=100_sparsity=0.95\" # 33_handcrafted\" # 9\" # \n",
    "model_names = [name for name in sorted(listdir(data_dir)) if isdir(join(data_dir, name))]\n",
    "print(model_names)\n",
    "N_models = len(model_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load local SSM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "test_results = []\n",
    "for model_name in model_names:\n",
    "    model_dir = join(data_dir, model_name, f\"SSMmodel_{observables}_ROMOrder={ROMOrder}_globalV\")\n",
    "    with open(join(model_dir, \"SSM_model.pkl\"), \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "        models.append(model)\n",
    "    with open(join(model_dir, \"test_results.yaml\"), \"rb\") as f:\n",
    "        test_results_dict = yaml.safe_load(f)\n",
    "        test_results.append([test_results_dict['like training data']['RMSE'], test_results_dict['open-loop_circle']['RMSE']])\n",
    "V = [model['model']['V'] for model in models]\n",
    "r_coeff = [model['model']['r_coeff'] for model in models]\n",
    "w_coeff = [model['model']['w_coeff'] for model in models]\n",
    "v_coeff = [model['model']['v_coeff'] for model in models]\n",
    "B_r = [model['model']['B'] for model in models]\n",
    "q_bar = [(model['model']['q_eq'] - rest_q)[TIP_NODE*3:TIP_NODE*3+3] for model in models]\n",
    "u_bar = [model['model']['u_eq'] for model in models]\n",
    "ROMOrder = models[0]['params']['ROM_order']\n",
    "SSMOrder = models[0]['params']['SSM_order']\n",
    "for model in models:\n",
    "    assert model['params']['ROM_order'] == ROMOrder\n",
    "    assert model['params']['SSM_order'] == SSMOrder\n",
    "test_results = np.array(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([150.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0.,   0., 150.,   0.]), array([  0.,   0.,   0., 300., 150.,   0.,   0.,   0.]), array([300., 150.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0., 150.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0., 150.,   0., 300.,   0.,   0., 150.]), array([  0., 300.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0., 150.,   0.,   0.,   0.,   0.,   0., 300.]), array([  0.,   0., 150.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0., 300.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0.,   0., 300.,   0.]), array([  0.,   0.,   0.,   0.,   0., 150.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300.,   0., 300.,   0.]), array([  0.,   0.,   0.,   0., 300.,   0.,   0.,   0.]), array([  0., 150., 150.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 300.]), array([  0.,   0., 300.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0., 300., 300.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 150.,   0.,   0.,   0.]), array([300.,   0., 150.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0., 300.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 150.]), array([150.,   0.,   0.,   0.,   0.,   0.,   0., 300.]), array([  0.,   0.,   0., 150.,   0.,   0.,   0.,   0.]), array([  0.,   0., 300.,   0., 300.,   0.,   0.,   0.]), array([  0.,   0., 150.,   0.,   0.,   0.,   0., 150.]), array([150.,   0.,   0.,   0., 300.,   0.,   0.,   0.]), array([  0.,   0., 300., 300.,   0.,   0.,   0.,   0.]), array([300.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300.,   0., 150., 300.]), array([  0.,   0.,   0., 150.,   0.,   0.,   0., 300.]), array([  0.,   0., 300.,   0.,   0.,   0., 300.,   0.]), array([  0., 150.,   0., 150.,   0.,   0.,   0.,   0.]), array([150.,   0.,   0., 300.,   0.,   0.,   0.,   0.]), array([300.,   0.,   0., 300.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 150., 300.,   0., 300.]), array([300., 150.,   0.,   0., 150.,   0.,   0.,   0.]), array([  0., 300.,   0.,   0., 300.,   0.,   0.,   0.]), array([  0.,   0.,   0., 300.,   0., 150.,   0., 300.]), array([  0., 150., 300.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 150.,   0.,   0., 300.]), array([  0.,   0.,   0.,   0.,   0., 150., 300.,   0.]), array([300.,   0.,   0.,   0.,   0.,   0., 300.,   0.]), array([300., 300.,   0.,   0.,   0.,   0.,   0.,   0.]), array([300.,   0.,   0.,   0., 150., 150.,   0.,   0.]), array([300.,   0.,   0.,   0.,   0., 300.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0., 300., 150.,   0.]), array([  0.,   0.,   0., 150.,   0.,   0., 150.,   0.]), array([  0., 300.,   0.,   0.,   0.,   0.,   0., 300.]), array([  0.,   0.,   0., 300.,   0., 300.,   0.,   0.]), array([  0.,   0.,   0., 300.,   0.,   0.,   0., 150.]), array([  0., 300., 300.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300., 150., 300.,   0.]), array([  0., 300.,   0.,   0.,   0.,   0.,   0., 150.]), array([150.,   0.,   0., 300.,   0., 300.,   0.,   0.]), array([  0., 300.,   0.,   0.,   0., 150.,   0.,   0.]), array([  0.,   0.,   0., 150.,   0., 150.,   0.,   0.]), array([300.,   0.,   0.,   0.,   0.,   0.,   0., 150.]), array([  0., 300.,   0., 300.,   0.,   0.,   0.,   0.]), array([150.,   0.,   0.,   0.,   0.,   0.,   0., 150.]), array([  0.,   0.,   0.,   0., 150.,   0., 300.,   0.]), array([  0., 150.,   0.,   0.,   0., 150.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0., 150.,   0., 150.]), array([  0.,   0., 300.,   0., 150.,   0.,   0.,   0.]), array([  0.,   0.,   0., 300.,   0.,   0.,   0., 300.]), array([  0.,   0.,   0.,   0.,   0., 300.,   0., 300.]), array([  0.,   0.,   0., 150., 150.,   0.,   0.,   0.]), array([  0., 150.,   0.,   0., 300.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300.,   0., 150.,   0.]), array([150.,   0.,   0.,   0.,   0., 150.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300.,   0.,   0., 150.]), array([300., 150.,   0.,   0.,   0.,   0.,   0., 150.]), array([300.,   0.,   0.,   0., 300.,   0.,   0.,   0.]), array([  0., 300.,   0.,   0.,   0.,   0., 300.,   0.]), array([150., 300.,   0.,   0.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0., 300., 150.,   0.,   0.]), array([  0.,   0., 150.,   0.,   0., 300.,   0.,   0.]), array([300.,   0.,   0.,   0.,   0., 150.,   0.,   0.]), array([  0., 300.,   0.,   0.,   0., 150.,   0., 300.]), array([300.,   0., 300.,   0.,   0.,   0.,   0.,   0.]), array([150.,   0.,   0.,   0., 150.,   0.,   0.,   0.]), array([  0.,   0., 150., 150.,   0.,   0.,   0.,   0.]), array([  0.,   0., 150.,   0.,   0.,   0., 300.,   0.]), array([  0.,   0.,   0., 300.,   0.,   0., 300.,   0.]), array([300.,   0.,   0.,   0.,   0.,   0.,   0., 300.]), array([  0.,   0.,   0.,   0., 300.,   0., 300., 150.]), array([  0.,   0.,   0.,   0.,   0., 150., 150., 300.]), array([  0.,   0., 150., 300.,   0.,   0.,   0.,   0.]), array([150.,   0.,   0.,   0.,   0.,   0., 300.,   0.]), array([  0., 150., 150.,   0., 300.,   0.,   0.,   0.]), array([  0., 150.,   0.,   0., 150.,   0.,   0.,   0.]), array([  0.,   0., 300., 150.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0.,   0., 300., 300.]), array([  0., 300.,   0.,   0.,   0.,   0., 150.,   0.]), array([300.,   0.,   0., 150.,   0.,   0.,   0.,   0.]), array([  0.,   0.,   0.,   0.,   0., 150., 150.,   0.]), array([  0.,   0.,   0., 300.,   0., 150.,   0.,   0.]), array([  0.,   0.,   0., 150.,   0.,   0., 300.,   0.]), array([300.,   0.,   0.,   0., 150.,   0.,   0.,   0.])]\n",
      "[8 7 7 6 6 7 5 7 6 7 7 7 7 6 7 6 7 7 6 7 6 7 7 6 7 6 6 6 6 7 5 6 6 6 6 6 5 5 6 5 6 6 6 6 6 5 6 6 6\n",
      " 6 6 6 6 5 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 5 6 6 6 6 6 6 5 5 6 6 5 6 6 6 6 6 6 6\n",
      " 6 6]\n",
      "6.05\n"
     ]
    }
   ],
   "source": [
    "if INTERPOLATE_3D:\n",
    "    xyz_rest = [q_bar[i][:3] for i in range(N_models)]\n",
    "else:\n",
    "    xyz_rest = [q_bar[i][:2] for i in range(N_models)]\n",
    "# xyz_rest\n",
    "print(u_bar)\n",
    "print(np.sum([u == 0 for u in u_bar], axis=1))\n",
    "print(np.mean(np.sum([u == 0 for u in u_bar], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "\n",
    "R_linear_part = [r[:, :6] for r in r_coeff]\n",
    "eigenvalues_real_part = [np.real(np.linalg.eigvals(r)) for r in R_linear_part]\n",
    "metric = [np.linalg.norm(eigenvalues, ord=-np.inf) for eigenvalues in eigenvalues_real_part]\n",
    "# metric = [-np.max(eigenvalues) for eigenvalues in eigenvalues_real_part]\n",
    "# metric = [np.linalg.norm(B, ord='nuc') for B in B_r]\n",
    "# metric = test_results[:, 1]\n",
    "# print(metric)\n",
    "# print(eigenvalues_real_part[24])\n",
    "# print(eigenvalues_real_part[55])\n",
    "\n",
    "# metric = test_results[:, 0]\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('rg',[\"forestgreen\", \"gold\", \"firebrick\"], N=256)\n",
    "\n",
    "rest_q = np.array(xyz_rest)\n",
    "\n",
    "if INTERPOLATE_3D:\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    sc = ax.scatter(rest_q[:, 0], rest_q[:, 1], rest_q[:, 2], marker=\"o\", c=metric, vmax=None, cmap='viridis') # color=\"tab:blue\")\n",
    "    for i in range(N_models):\n",
    "        ax.text(rest_q[i, 0], rest_q[i, 1], rest_q[i, 2], str(i), size=10, zorder=1, color='k')\n",
    "    ax.set_zlabel(r\"$z$ [mm]\")\n",
    "else:\n",
    "    ax = plt.axes()\n",
    "    sc = ax.scatter(rest_q[:, 0], rest_q[:, 1], marker=\"o\", c=metric, vmax=None, cmap=cmap) # color=\"tab:blue\")\n",
    "ax.set_xlabel(r\"$x$ [mm]\")\n",
    "ax.set_ylabel(r\"$y$ [mm]\")\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.colorbar(sc, ax=ax, label=r\"$||Re(\\lambda)||_{\\infty}$\")\n",
    "fig.suptitle(\"Slowest decay mode of the ROM's linear part\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out _\"bad\"_ models:\n",
    "- opposite side actuation\n",
    "- very fast decay modes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"good\" models: 53/100\n",
      "Indices of \"bad\" models: (array([ 3,  4,  7, 10, 17, 18, 20, 24, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41, 44, 46, 51, 52,\n",
      "       54, 55, 56, 57, 58, 64, 72, 73, 74, 75, 78, 79, 82, 83, 84, 85, 86, 88, 90, 92, 94, 95, 97,\n",
      "       99]),)\n"
     ]
    }
   ],
   "source": [
    "bad_models = np.isnan(test_results[:, 1])\n",
    "# bad_models = np.isnan(test_results[:, 1]) | (test_results[:, 1] > 10)\n",
    "\n",
    "print(f'Number of \"good\" models: {np.sum(~bad_models)}/{len(model_names)}')\n",
    "print(f'Indices of \"bad\" models: {np.nonzero(bad_models)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_models = [0, 1, 2, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 19, 21, 22, 23, 25, 26, 27, 31, 33, 36, 42, 43, 45, 47, 48, 49, 50, 53, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 76, 77, 80, 81, 87, 89, 91, 93, 96, 98]\n"
     ]
    }
   ],
   "source": [
    "# use_models = [0, 81, 62, 73, 32, 65, 99, 56, 51, 27, 83, 31]\n",
    "use_models = [int(model_name) for model_name in model_names if not bad_models[int(model_name)]]\n",
    "print(f\"use_models = {use_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep models\n",
    "for i in range(N_models):\n",
    "    if i not in use_models:\n",
    "        V[i] = None\n",
    "        r_coeff[i] = None\n",
    "        w_coeff[i] = None\n",
    "        v_coeff[i] = None\n",
    "        B_r[i] = None\n",
    "        q_bar[i] = None\n",
    "        u_bar[i] = None\n",
    "        xyz_rest[i] = None\n",
    "V = [V[i] for i in range(len(V)) if V[i] is not None]\n",
    "r_coeff = [r_coeff[i] for i in range(len(r_coeff)) if r_coeff[i] is not None]\n",
    "w_coeff = [w_coeff[i] for i in range(len(w_coeff)) if w_coeff[i] is not None]\n",
    "v_coeff = [v_coeff[i] for i in range(len(v_coeff)) if v_coeff[i] is not None]\n",
    "B_r = [B_r[i] for i in range(len(B_r)) if B_r[i] is not None]\n",
    "q_bar = [q_bar[i] for i in range(len(q_bar)) if q_bar[i] is not None]\n",
    "u_bar = [u_bar[i] for i in range(len(u_bar)) if u_bar[i] is not None]\n",
    "xyz_rest = [xyz_rest[i] for i in range(len(xyz_rest)) if xyz_rest[i] is not None]\n",
    "N_models = len(V)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute observables (delay embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if observables == \"delay-embedding\":\n",
    "    N_DELAY = 4\n",
    "    # observables are position of tip + n_delay delay embeddings of the tip position\n",
    "    assemble_observables = lambda oData: utils.delayEmbedding(oData, up_to_delay=N_DELAY)\n",
    "elif observables == \"pos-vel\":\n",
    "    # observables is position and velocity of tip node\n",
    "    def assemble_observables(oData):\n",
    "        if oData.shape[0] > 6:\n",
    "            tip_node_slice = np.s_[3*TIP_NODE:3*TIP_NODE+3]\n",
    "        else:\n",
    "            tip_node_slice = np.s_[:3]\n",
    "        return np.vstack((oData[tip_node_slice, :], np.gradient(oData[tip_node_slice, :], DT, axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test trajectory (for now: sum of all trajectories used to regress B matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 20001)\n"
     ]
    }
   ],
   "source": [
    "# test_trajectory_dir = \"open-loop\"\n",
    "test_trajectories = []\n",
    "# for name in tqdm(model_names): # ['origin']: # \n",
    "traj_dir = \"/home/jonas/Projects/stanford/soft-robot-control/examples/trunk/dataCollection/open-loop_500\" # join(model_dir, name, test_trajectory_dir)\n",
    "(t, z), u = utils.import_pos_data(data_dir=traj_dir,\n",
    "                                  rest_file=rest_file,\n",
    "                                  output_node=TIP_NODE, return_inputs=True, traj_index=0)\n",
    "y = assemble_observables(z)\n",
    "print(y.shape)\n",
    "test_trajectories.append({\n",
    "        'name': split(traj_dir)[-1],\n",
    "        't': t,\n",
    "        'z': z,\n",
    "        'u': u,\n",
    "        'y': y\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine into one long trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tot = np.hstack([traj['z'] for traj in test_trajectories])\n",
    "y_tot = np.hstack([traj['y'] for traj in test_trajectories])\n",
    "u_tot = np.hstack([traj['u'] for traj in test_trajectories])\n",
    "t_tot = np.arange(z_tot.shape[1]) * DT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate local models to obtain adiabatic SSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "interpolation_methods = [\"idw\", \"origin_only\", \"linear\"] # , \"natural_neighbor\"] # [\"origin_only\", \"linear\", \"ct\", \"idw\", \"qp\"] # , \"ridge\"] # [ \"rmts\", \"idw\", \"qp\"]\n",
    "coeff_dict = {\n",
    "            'w_coeff': w_coeff,\n",
    "            'V': V,\n",
    "            'r_coeff': r_coeff,\n",
    "            'B_r': B_r,\n",
    "            'u_bar': u_bar,\n",
    "            'q_bar': q_bar\n",
    "        }\n",
    "\n",
    "print(len(xyz_rest))\n",
    "# if v_coeff:\n",
    "#     coeff_dict['v_coeff'] = v_coeff\n",
    "interpolators = {}\n",
    "for interpolation_method in interpolation_methods:\n",
    "    interpolators[interpolation_method] = InterpolatorFactory(interpolation_method, xyz_rest, coeff_dict).get_interpolator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_names = {\n",
    "    \"origin_only\": \"Origin model\",\n",
    "    \"linear\": \"Barycentric linear\",\n",
    "    \"ct\": \"Clough-Tocher\",\n",
    "    \"idw\": \"Inverse distance weighting\",\n",
    "    \"qp\": \"Quadratic regression\",\n",
    "    \"natural_neighbor\": \"Natural neighbor\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INTERPOLATE_3D:\n",
    "    nx, ny = (100, 100)\n",
    "    x = np.linspace(-50, 50, nx)\n",
    "    y = np.linspace(-50, 50, ny)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    # xy = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "    coeff = \"r_coeff\"\n",
    "    entry = np.s_[0, 0]\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(1, len(interpolation_methods), figsize=(20, 4), subplot_kw={\"projection\": \"3d\"})\n",
    "    for i, interpolation_method in enumerate(interpolation_methods):\n",
    "        ax = axs[i]\n",
    "        z = np.zeros((nx, ny))\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                z[i, j] = interpolators[interpolation_method].transform([xv[i, j], yv[i, j]], coeff)[entry]\n",
    "        ax.plot_surface(xv, yv, z, cmap=\"viridis\", vmin=-3.6, vmax=-3.2)\n",
    "        ax.set_xlabel(r\"$x$ [mm]\")\n",
    "        ax.set_ylabel(r\"$y$ [mm]\")\n",
    "        ax.set_zlabel(r\"$R[0, 0]$\")\n",
    "        ax.set_zlim(-3.6, -3.2)\n",
    "        # ax.view_init(90, -90)\n",
    "        ax.set_title(display_names[interpolation_method])\n",
    "    fig.savefig(join(traj_dir, f\"interpolation_landscapes_2d.png\"), bbox_inches='tight', dpi=200)\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample finite-horizon predictions to evaluate interpolated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_horizon = 5\n",
    "N_samples = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20001)\n"
     ]
    }
   ],
   "source": [
    "print(z_tot.shape)\n",
    "np.random.seed(seed=0)\n",
    "sample_indices = randint(0, z_tot.shape[1], N_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc6c8d6cd04b9bbed629758684ba78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== idw ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3365dc4dd7c645a99297e1781b73bd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max RMSE: 0.8517890791383443\n",
      "==================== origin_only ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805ce8818f194f4abfb802f33b12f9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max RMSE: 2.6155866979927898\n",
      "==================== linear ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180e04a11edb4c9589b384e1dc3e1259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# advect ASSM to obtain finite-horizon prediction\u001b[39;00m\n\u001b[1;32m     14\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m t, _, y_pred, _, _, _, _ \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49madvect_adiabaticRD_with_inputs(t_tot[start_idx:end_idx], y_tot[:, start_idx], u_tot[:, start_idx:end_idx],\n\u001b[1;32m     16\u001b[0m                                                                 y_target\u001b[39m=\u001b[39;49my_tot[:, start_idx:end_idx], interpolator\u001b[39m=\u001b[39;49minterpolators[interpolation_method],\n\u001b[1;32m     17\u001b[0m                                                                 ROMOrder\u001b[39m=\u001b[39;49mROMOrder)\n\u001b[1;32m     18\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m \u001b[39m# compute RMSE\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/stanford/SSMR-for-control/ROM/python/utils.py:362\u001b[0m, in \u001b[0;36madvect_adiabaticRD_with_inputs\u001b[0;34m(t, y0, u, y_target, interpolator, ROMOrder, SSMDim, know_target)\u001b[0m\n\u001b[1;32m    345\u001b[0m             y_target[:, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m y_pred[:, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    347\u001b[0m         \u001b[39m# print(\"i =\", i)\u001b[39;00m\n\u001b[1;32m    348\u001b[0m         \u001b[39m# print(\"y_pred[i-1]:\", y_pred[:, i-1])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[39m# print(e)\u001b[39;00m\n\u001b[1;32m    361\u001b[0m         \u001b[39m# break\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m t, x, y_pred, xdot, y_bar, u_bar, weights\n",
      "File \u001b[0;32m~/Projects/stanford/SSMR-for-control/ROM/python/utils.py:339\u001b[0m, in \u001b[0;36madvect_adiabaticRD_with_inputs\u001b[0;34m(t, y0, u, y_target, interpolator, ROMOrder, SSMDim, know_target)\u001b[0m\n\u001b[1;32m    337\u001b[0m     x[:, i] \u001b[39m=\u001b[39m transform(xy, \u001b[39m'\u001b[39m\u001b[39mV\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (y0 \u001b[39m-\u001b[39m y_bar[:, i]) \u001b[39m# (transform(xy, 'v_coeff') @ phi((y0 - y_bar[:, i]).reshape(-1, 1), 3)).flatten() # y[:, i]) # \u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# xdot[i] = R(x[i]) + B[i] @ (u[i] - u_bar[i])\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m xdot[:, i] \u001b[39m=\u001b[39m (transform(xy, \u001b[39m'\u001b[39m\u001b[39mr_coeff\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m@\u001b[39m phi(x[:, i]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m), ROMOrder))\u001b[39m.\u001b[39mflatten() \u001b[39m+\u001b[39m transform(xy, \u001b[39m'\u001b[39m\u001b[39mB_r\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m@\u001b[39m (u[:, i] \u001b[39m-\u001b[39m u_bar[:, i]) \u001b[39m# -0.5 * np.eye(6) @ x[:, i] # -0.001 * np.ones(6) # \u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39m# forward Euler: x[i+1] = x[i] + dt * xdot[i]\u001b[39;00m\n\u001b[1;32m    341\u001b[0m x[:, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m x[:, i] \u001b[39m+\u001b[39m dt \u001b[39m*\u001b[39m xdot[:, i]\n",
      "File \u001b[0;32m~/Projects/stanford/SSMR-for-control/ROM/python/utils.py:37\u001b[0m, in \u001b[0;36mphi\u001b[0;34m(x, order)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(order, \u001b[39mint\u001b[39m):\n\u001b[1;32m     36\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(order)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m PolynomialFeatures(degree\u001b[39m=\u001b[39;49morder, include_bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39;49mfit_transform(x\u001b[39m.\u001b[39;49mT)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/preprocessing/_polynomial.py:252\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mCompute number of output features.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39m    Fitted transformer.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 252\u001b[0m _, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mshape\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree, Integral):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/soft/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for interpolation_method in tqdm(interpolation_methods, position=0):\n",
    "    print(f\"==================== {interpolation_method} ====================\")\n",
    "    q_samples = []\n",
    "    rmse_samples = []\n",
    "    advect_times = []\n",
    "    for i in tqdm(range(N_samples), position=1, leave=True):\n",
    "        start_idx = sample_indices[i]\n",
    "        end_idx = start_idx + N_horizon\n",
    "        q_samples.append(z_tot[:3, start_idx])\n",
    "        # advect ASSM to obtain finite-horizon prediction\n",
    "        t0 = time.time()\n",
    "        t, _, y_pred, _, _, _, _ = utils.advect_adiabaticRD_with_inputs(t_tot[start_idx:end_idx], y_tot[:, start_idx], u_tot[:, start_idx:end_idx],\n",
    "                                                                        y_target=y_tot[:, start_idx:end_idx], interpolator=interpolators[interpolation_method],\n",
    "                                                                        ROMOrder=ROMOrder)\n",
    "        t1 = time.time()\n",
    "        # compute RMSE\n",
    "        rmse = np.sum(np.sqrt(np.mean((y_tot[:3, start_idx:end_idx] - y_pred[:3, :])**2, axis=0))) / N_horizon\n",
    "        rmse_samples.append(rmse)\n",
    "        advect_times.append(t1 - t0)\n",
    "    # max_rmse_index = np.argmax(rmse_samples)\n",
    "    print(\"max RMSE:\", np.nanmax(rmse_samples))\n",
    "    # print(\"max RMSE sample idx:\", sample_indices[max_rmse_index])\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_rmse_samples.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(rmse_samples, f)\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_q_samples.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(q_samples, f)\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_advect_times.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(advect_times, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prediction accuracy maps for all the different interpolation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_methods = [\"origin_only\", \"linear\", \"ct\", \"idw\", \"natural_neighbor\"] # [\"origin_only\", \"linear\", \"nn\", \"qp\"] # , \"tps\", \"ls\", \"qp\"]\n",
    "fig, axs = plt.subplots(3, len(interpolation_methods),\n",
    "                        figsize=(4*len(interpolation_methods), 7),\n",
    "                        height_ratios=[5, 2, 2],\n",
    "                        sharey='row', sharex='row', constrained_layout=True)\n",
    "for i, interpolation_method in enumerate(interpolation_methods):\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_rmse_samples.pkl\"), \"rb\") as f:\n",
    "        rmse_samples = np.array(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_q_samples.pkl\"), \"rb\") as f:\n",
    "        q_samples = np.stack(pickle.load(f))\n",
    "    with open(join(traj_dir, f\"{interpolation_method}_advect_times.pkl\"), \"rb\") as f:\n",
    "        advect_times = np.array(pickle.load(f))\n",
    "    colorbar = (i == len(interpolation_methods) - 1)\n",
    "    plot.prediction_accuracy_map(q_samples[:, [0, 1]], rmse_samples, vmax=.6, ax=axs[0, i], colorbar=colorbar, cax=axs[:, :], show=False)\n",
    "    plot.boxplot(rmse_samples, ax=axs[1, i], show=False, xlabel=\"RMSE [mm]\")\n",
    "    plot.boxplot(advect_times, ax=axs[2, i], show=False, xlabel=\"Advect time [s]\")\n",
    "    axs[0, i].set_title(display_names[interpolation_method])\n",
    "    # if i > 0:\n",
    "    #     axs[0, i].set_ylabel(\"\")\n",
    "# fig.tight_layout()\n",
    "fig.savefig(join(traj_dir, f\"prediction_accuracy.png\"), bbox_inches='tight', dpi=200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
